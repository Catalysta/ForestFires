---
title: "forestfires_analysis"
author: "Christina Sousa"
date: "April 3, 2019"
output: html_document
---

Subset the data to train the model, reserving 1/4 for validation. Use same indices as those used in logistic regression.


```{r augment}

#add quadratic, cubic, and interaction terms
quad<-(forest6[,6:12])^2
labels.quad<-colnames(forest6[,6:12])
labels.quad<-paste(labels.quad,"^2")
colnames(quad)<-labels.quad
cubic<-(forest6[,6:12])^3
labels.cubic<-colnames(forest6[,6:12])
labels.cubic<-paste(labels.cubic,"^3")
colnames(cubic)<-labels.cubic

two.way.interaction<-matrix(nrow=nrow(forest6),ncol=21)
labels2<-vector()
#create interaction terms
k=1
for(i in 6:11){
  for (j in (i+1):12){
    two.way.interaction[,k]<-forest6[,i]*forest6[,j]
    labels2[k]<-paste(colnames(forest6)[i],colnames(forest6)[j], sep = "*")
    k<-(k+1)
  }
}
colnames(two.way.interaction)<-labels2

three.way.interaction<-matrix(nrow=nrow(forest6),ncol=35)
labels<-vector()
#create interaction terms
m=1
for(i in 6:10){
  for (j in (i+1):11){
    for (k in (j+1):12){
      three.way.interaction[,m]<-forest6[,i]*forest6[,j]*forest6[,k]
      labels[m]<-paste(colnames(forest6)[i],colnames(forest6)[j],colnames(forest6)[k], sep = "*")
      m<-(m+1)
    }
  }
}
colnames(three.way.interaction)<-labels

forest6.augmented<-cbind(forest6,quad,cubic,two.way.interaction,three.way.interaction)
```

```{r split}
set.seed(6950)
indices<-sample(1:270,203)
train<-forest6.augmented[indices,]
test<-forest6.augmented[-indices,]
pairs(train[,6:13])
```

```{r vif}
#please run all chunks from EDA prior to running this document.

#Check VIF since data appears to present with high multicollinearity

#set up regression models

cts.pred<-train[,6:12]
q<-ncol(cts.pred)
r2k<-numeric(q)
for (i in 1:q){
  formula<-as.formula(paste(colnames(cts.pred)[i],"~."))
  model<-lm(formula,data = cts.pred)
  r2k[i]<-summary(model)$r.squared
}
vifk<-1/(1-r2k)
vifk #these actually don't look too bad (but not great either)

#regress DMC on DC
summary(lm(DMC~DC, dat=train))$r.squared #actually not too bad, ok to leave in.

#check cook's distances
cd<-cooks.distance(lm(Larea~.,dat=train))
which(cd>qf(0.5,ncol(train)+1,nrow(train)-ncol(train)-1)) #these also look fine
boxplot(cd, main = "Cooks Distance (MLR)")
#abline(v=qf(0.5,ncol(train)+1,nrow(train)-ncol(train)-1))

```


```{r LASSO}

#try LASSO on augmented prediction set
require(glmnet)
X<-model.matrix(Larea~.-1,data=train)
y<-train$Larea

cvfit<-cv.glmnet(X, y, nfolds=5)
plot(cvfit)
coef(cvfit, s = "lambda.min")

fit.lasso<-glmnet(X,y,alpha=1)
plot(fit.lasso,xvar="lambda",label=TRUE)

#try leaving out Spatial and Temporal predictors
X<-model.matrix(Larea~.-1,data=train[,c(6:13,16:85)])
y<-train$Larea

cvfit2<-cv.glmnet(X, y, nfolds=5)
plot(cvfit2)
coef(cvfit2, s = "lambda.min")

fit.lasso2<-glmnet(X,y,alpha=1)
plot(fit.lasso2,xvar="lambda",label=TRUE)

yhat<-predict(cvfit2,X,s="lambda.min")
mean((y-yhat)^2)
```

Since p is small, we enumerate full model space using `leaps` package.

```{r regsub}
require(leaps)
y<-train$Larea
X<-train[,c(1:12,14:15)]
regsubsets.out=regsubsets(y ~ X,
			   data = as.data.frame(cbind(y,X)),
               nbest = 2,       # 2 best models for each number of predictors
               nvmax = NULL,    # NULL for no limit on number of variables
               force.in = NULL, force.out = NULL,
               method = "exhaustive") # or "forward" for forward selection,
                                      # "backward" for backward elimination
regsubsets.out
sum.reg=summary(regsubsets.out)
sum.reg

```

`DMC` appears to be least important, while `month` and `day` appear to be important. R^2 is extremely low. This data simply does not seem to predict `Larea` very well.

```{r plot regsub}
par(mfrow=c(1,3))
plot(regsubsets.out, scale = "r2", main = "R^2",cex.axis=2,cex.lab=2,cex=2)
plot(regsubsets.out, scale = "adjr2", main = "Adjusted R^2",cex.axis=2,cex.lab=2,cex=2)
plot(regsubsets.out, scale = "Cp", main = "Mallow's Cp",cex.axis=2,cex.lab=2,cex=2)
```

```{r select1}
#try forward/backward selection on the augmented data
fit0<-lm(Larea~1,dat=train)
fitfull<-lm(Larea~.,dat=train)

# Forward selection
step(fit0,scope=list(lower=fit0,upper=fitfull),direction="forward")

# Backward elimination
step(fitfull,scope=list(lower=fit0,upper=fitfull),direction="backward")

# Stepwise regression
step(fit0,scope=list(lower=fit0,upper=fitfull),direction="both")
```

```{r select1mod}
fwd.model<-lm(formula = Larea ~ ISI:temp:RH + DMC:ISI + TrFFMC:DMC:ISI + 
    week, data = train)
summary(fwd.model)

bwd.model<-lm(formula = Larea ~ XY + month + day + TrFFMC + DMC + temp + 
    RH + wind + `TrFFMC ^2` + `DC ^2` + `RH ^2` + `wind ^2` + 
    `TrFFMC ^3` + `DC ^3` + `ISI ^3` + `RH ^3` + `TrFFMC*DMC` + 
    `TrFFMC*DC` + `TrFFMC*ISI` + `TrFFMC*temp` + `TrFFMC*RH` + 
    `TrFFMC*wind` + `DMC*DC` + `DMC*ISI` + `DMC*temp` + `DMC*RH` + 
    `DMC*wind` + `DC*temp` + `DC*wind` + `ISI*temp` + `ISI*wind` + 
    `temp*RH` + `temp*wind` + `RH*wind` + `TrFFMC*DMC*DC` + `TrFFMC*DMC*temp` + 
    `TrFFMC*DC*ISI` + `TrFFMC*DC*temp` + `TrFFMC*DC*RH` + `TrFFMC*DC*wind` + 
    `TrFFMC*ISI*temp` + `TrFFMC*ISI*RH` + `TrFFMC*temp*RH` + 
    `TrFFMC*temp*wind` + `TrFFMC*RH*wind` + `DMC*DC*ISI` + `DMC*DC*RH` + 
    `DMC*ISI*wind` + `DMC*temp*RH` + `DMC*temp*wind` + `DMC*RH*wind` + 
    `DC*ISI*temp` + `DC*ISI*wind` + `DC*temp*RH` + `ISI*temp*RH` + 
    `ISI*temp*wind` + `ISI*RH*wind`, data = train)
summary(bwd.model)

stepwise.model<-lm(formula = Larea ~ ISI:temp:RH + DMC:ISI + TrFFMC:DMC:ISI + 
    week, data = train)
summary(stepwise.model)

```


```{r select2, echo=F}
#try forward/backward selection, augmented, leave out Spatial/Temporal predictors.
fit0<-lm(Larea~1,dat=train[,c(6:13,16:85)])
fitfull<-lm(Larea~.,dat=train[,c(6:13,16:85)])

# Forward selection
step(fit0,scope=list(lower=fit0,upper=fitfull),direction="forward")

# Backward elimination
step(fitfull,scope=list(lower=fit0,upper=fitfull),direction="backward")

# Stepwise regression
step(fit0,scope=list(lower=fit0,upper=fitfull),direction="both")
```


```{r select2mod}
fwd.weather.model<-lm(formula = Larea ~ ISI:temp:RH + DMC:ISI + TrFFMC:DMC:ISI, 
    data = train[, c(6:13, 16:85)])
summary(fwd.weather.model)

fwd.weather.model.hierarchy<-lm(formula = Larea ~ ISI+temp+RH+DMC+TrFFMC+ISI:temp+temp:RH+ISI:RH+ISI:temp:RH + DMC:ISI + TrFFMC:DMC + TrFFMC:ISI+ TrFFMC:DMC:ISI, 
    data = train[, c(6:13, 16:85)])
summary(fwd.weather.model.hierarchy)

bwd.weather.model<-lm(formula = Larea ~ TrFFMC + DMC + wind + `TrFFMC ^2` + `DC ^2` + 
    `ISI ^2` + `RH ^2` + `TrFFMC ^3` + `DC ^3` + `RH ^3` + `TrFFMC*DMC` + 
    `TrFFMC*DC` + `TrFFMC*ISI` + `TrFFMC*RH` + `TrFFMC*wind` + 
    `DMC*DC` + `DMC*ISI` + `DMC*temp` + `DMC*wind` + `DC*ISI` + 
    `DC*temp` + `DC*wind` + `ISI*temp` + `ISI*wind` + `temp*wind` + 
    `TrFFMC*DC*temp` + `TrFFMC*DC*wind` + `TrFFMC*ISI*temp` + 
    `TrFFMC*ISI*RH` + `TrFFMC*temp*RH` + `TrFFMC*RH*wind` + `DMC*DC*temp` + 
    `DMC*ISI*temp` + `DMC*temp*wind` + `DC*ISI*temp` + `DC*ISI*RH` + 
    `DC*ISI*wind` + `DC*temp*RH` + `temp*RH*wind`, data = train[, 
    c(6:13, 16:85)])
summary(bwd.weather.model)


stepwise.weather.model<-lm(formula = Larea ~ `ISI*temp*RH` + `DMC*ISI` + `TrFFMC*DMC*ISI`, 
    data = train[, c(6:13, 16:85)])
summary(stepwise.weather.model)

y<-train$Larea
yhat3<-predict(fwd.weather.model,X=train[,c(6:13,16:85)])
mean((y-yhat3)^2)
yhat2<-predict(bwd.weather.model,X=train[,c(6:13,16:85)])
in.sample.MSE.bwd.weather.model<-mean((y-yhat2)^2)
yhat4<-predict(stepwise.weather.model,X=train[,c(6:13,16:85)])
mean((y-yhat4)^2)
```

Use the weather variable model arising from backward selection as it achieves the highest adjusted R^2 and lowest MSE. Check diagnostics

```{r diagnostics}
resids<-resid(bwd.weather.model)
fitted.vals<-fitted(bwd.weather.model)
plot(fitted.vals, resids, main = "Fitted Values versus Residuals, MLR")
abline(h=0)

qqnorm(resids)
qqline(resids, col="blue")

```

```{r testing}
#get test performance
y<-test$Larea
yhat4<-predict(bwd.weather.model,newdata=test[,c(6:13,16:85)])
pred.MSE.bwd.weather.model<-mean((y-yhat4)^2)
in.sample.MSE.bwd.weather.model
pred.MSE.bwd.weather.model #suggests that model is overfit

#check test performace for mean model
mean.model<-mean(train$Larea)
in.sample.MSE.mean.model<-mean((train$Larea-rep(mean(train$Larea,203)))^2)
yhat5<-rep(mean(train$Larea),67)
pred.MSE.mean.model<-mean((y-yhat5)^2)

in.sample.MSE.mean.model
pred.MSE.mean.model

```