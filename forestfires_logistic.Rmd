---
title: "forestfires_logistic"
author: "Christina Sousa"
date: "April 4, 2019"
output: html_document
---

## Introduction

## Data

The variables in the data are given by:

   1. **X** *(nominal)*: x-axis spatial coordinate within the Montesinho park map: 1 to 9
   2. **Y** *(nominal)*: y-axis spatial coordinate within the Montesinho park map: 2 to 9
   3. **month** *(nominal)*: month of the year: "jan" to "dec" 
   4. **day** *(nominal)*: day of the week: "mon" to "sun"
   5. **FFMC** *(ordinal, continuous)*: FFMC index from the FWI system: 18.7 to 96.20
   6. **DMC** *(ordinal, continuous)*: DMC index from the FWI system: 1.1 to 291.3 
   7. **DC** *(ordinal, continuous)*: DC index from the FWI system: 7.9 to 860.6 
   8. **ISI** *(ordinal, continuous)*: ISI index from the FWI system: 0.0 to 56.10
   9. **temp** *(interval, continuous)*: temperature in Celsius degrees: 2.2 to 33.30
   10. **RH** *(ordinal, discrete)*: relative humidity in %: 15.0 to 100
   11. **wind** *(ratio, continuous)* wind speed in km/h: 0.40 to 9.40 
   12. **rain** *(ratio, discrete)*: outside rain in mm/m2 : 0.0 to 6.4 
   13. **area** *(ratio, continuous)*: the burned area of the forest (in ha): 0.00 to 1090.84 

```{r}
#data file can be obtained at https://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/
#read data into r
forest7 <-read.csv("forestfires.csv")

# obs 23 looks influential but the model is worse when you erase it
# forest7 <- forest7[-23,]
forest7$area <- log(forest7$area + 1)


#change spatial variables X and Y to factors
forest7$XY <- 10*forest7$X+forest7$Y
forest7$X<-as.factor(forest7$X)
forest7$Y<-as.factor(forest7$Y)
forest7$XY<-as.factor(as.integer(forest7$XY))
forest7<-forest7[,c(14,1:13)]
#add binomial area column
forest8<-cbind(forest7,forest7$area>0)
colnames(forest8)[15]<-"large"
forest8$large<-as.factor(forest8$large)

#add categorical rain column
forest9<-cbind(forest8,forest8$rain>0)
colnames(forest9)[16]<-"rainbin"
forest9$rain<-as.factor(forest9$rain)

#add categorical weekday and season variables
week <- rep(0,length(forest9$day))

week[which(forest9$day == "mon")] <- 0
week[which(forest9$day == "tue")] <- 0
week[which(forest9$day == "wed")] <- 0
week[which(forest9$day == "thu")] <- 0
week[which(forest9$day == "fri")] <- 1
week[which(forest9$day == "sat")] <- 1
week[which(forest9$day == "sun")] <- 1

seas <- rep(0,length(forest9$month), ylab = "log(area)",
     xlab = "Month",main = "Month Data")

seas[which(forest9$month == "jan")] <- 0
seas[which(forest9$month == "feb")] <- 0
seas[which(forest9$month == "mar")] <- 0
seas[which(forest9$month == "apr")] <- 1
seas[which(forest9$month == "may")] <- 1
seas[which(forest9$month == "jun")] <- 1
seas[which(forest9$month == "jul")] <- 2
seas[which(forest9$month == "aug")] <- 2
seas[which(forest9$month == "sep")] <- 2
seas[which(forest9$month == "oct")] <- 3
seas[which(forest9$month == "nov")] <- 3
seas[which(forest9$month == "dec")] <- 3

forest9$week <- as.factor(week)
levels(forest9$week)<-c("weekday","weekend")
forest9$season <- as.factor(seas)
levels(forest9$season)<-c("Winter","Spring","Summer","Fall")
```

```{r}
#clean up other variables

forest9$month = factor(forest9$month,
                       levels = levels(forest9$month)[c(5,                                                        4,8,1,9,7,6,2,12,11,10,3)])
forest9$day = factor(forest9$day,
                     levels = 
                       levels(forest9$day)[c(2,6,7,5,1,3,4)])

#pairs(forest9)
forest9 <- forest9[,c(1:13,16:18,14,15)]
pairs(forest9[,c(-2,-3,-4,-5)])


```

```{r}
#split training and testing set

set.seed(6950)

indices<-sample(1:517,388)
train2<-forest9[indices,]
test2<-forest9[-indices,]

train3<-train2[,c(-(1:3),-13,-(15:17))]

#view continuous predictors
pairs(train3[,3:9])

#transform FFMC
train4<-train3
train4$FFMC <- log(-train4$FFMC+ max(train4$FFMC)+1)
colnames(train4)[3]<-"TrFFMC"

pairs(train4[,3:9])

#check cook's distances
cd<-cooks.distance(glm(large~.,dat=train4,family="binomial"))
which(cd>qf(0.5,ncol(train2)+1,nrow(train2)-ncol(train2)-1)) #these look fine

#use deviance as a measure instead
#fill in algorithm

#remove outlier
train5<-train4[which(train3$ISI<40),]
pairs(train5[,3:9])

require(car)
summary(powerTransform(cbind(TrFFMC,DMC,DC,ISI,temp,RH,wind)~1,train5,family="yjPower"))

```

## Model Selection

```{r}

mylogit<-glm(formula = large ~ temp+RH+DC+ISI+DMC, family = "binomial", data = train2)
summary(mylogit)


mylogit<-glm(formula = large ~ XY+week+season+rain+
               wind+FFMC+temp+RH+DC+ISI+DMC,
             family = "binomial", data = train2)
summary(mylogit)


mylogit<-glm(formula = large ~ XY+week+season+rainbin+
               wind+FFMC+temp+RH+DC+ISI+DMC,
             family = "binomial", data = train2)
summary(mylogit)


mylogit<-glm(formula = large ~ week+season+rainbin+
               wind+FFMC+temp+RH+DC+ISI+DMC,
             family = "binomial", data = train2)
summary(mylogit)


mylogit<-glm(formula = large ~ week+season+rain+
               wind+FFMC+temp+RH+DC+ISI+DMC,
             family = "binomial", data = train2)
summary(mylogit)


mylogit<-glm(formula = large ~ season+rainbin+
               wind+FFMC+temp+RH+DC+ISI+DMC,
             family = "binomial", data = train2)
summary(mylogit)


mylogit<-glm(formula = large ~ wind+rainbin,
             family = "binomial", data = train2)
summary(mylogit)

```